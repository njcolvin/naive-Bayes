{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a naive Bayes classifier. We will run it on a collection of tweets and Reddit comments whose sentiment is either positive, neutral, or negative.\n",
    "\n",
    "First, let's load the data into training and test corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus():\n",
    "    with open('twitter.csv', 'r', encoding='latin-1') as f:\n",
    "        lines = f.readlines()\n",
    "    corpus = []\n",
    "    n = len(lines)\n",
    "    i = 1\n",
    "    while i < n:\n",
    "        line = lines[i]\n",
    "        xy = line.split(',')\n",
    "        x = xy[0].rstrip().split(' ')\n",
    "        if len(xy) == 1: # multiline tweet\n",
    "            line = lines[i][1:].rstrip() # remove double quote\n",
    "            i += 1\n",
    "            if len(line) == 0 and i < n:\n",
    "                # beginning of tweet so dont put space\n",
    "                line += lines[i].split(',')[0].rstrip()\n",
    "                i += 1\n",
    "            while i < n and len(lines[i].split(',')) == 1:\n",
    "                line += ' ' + lines[i].rstrip()\n",
    "                i += 1\n",
    "            xy = lines[i].split(',')\n",
    "            endsize = len(xy[0])\n",
    "            if endsize > 1: # ignore double quote i.e. endsize == 1\n",
    "                # remove double quote at the end\n",
    "                line += ' ' + xy[0][:endsize - 1] \n",
    "            x = line.split(' ')\n",
    "        y = int(xy[1].rstrip())\n",
    "        corpus.append([x, y])\n",
    "        i += 1\n",
    "    return corpus\n",
    "\n",
    "corpus = get_corpus()\n",
    "train = corpus[:int(len(corpus) * 0.8)]\n",
    "test = corpus[int(len(corpus) * 0.8):]\n",
    "classes = [-1, 0, 1] # negative, neutral, positive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our naive Bayes classifier class. All we really need is a train function and a test function.\n",
    "\n",
    "To train, we calculate the probabilities of each class, P(c), and of every feature (in our case individual words) given each class, P(w|c), using MLE and counting.\n",
    "\n",
    "The prior probability of a class P(c) will be defined as the number of documents (tweets) in class c out of all available documents.\n",
    "\n",
    "The likelihood of a feature given a class P(w|c) will be defined as the number of occurrences of w in documents in class c out of the number of occurrences of all words in documents in class c.\n",
    "\n",
    "For a test sample, we find the probability of the sample document given each class, P(d|c), and return the argmax class as our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to import a log function since we would rather add up log probabilities than multiply (lots of near zero) probabilities.\n",
    "\n",
    "We'll also need the Counter class to get frequency counts from our training corpus. Specifically, we're going to use a hyperparameter `vocab_size` to set our features as the `vocab_size` most common words in the corpus. These are the most common words in the entire corpus, not just for a class. \n",
    "\n",
    "Notice the additional `smoothing` parameter. Since we are using individual words as features, there's a chance during training we find a word that doesn't show up in any documents for a class and gets assigned zero probability. The computer will not like taking log of zero, and we will not like the model. To avoid this, we simply add the value of `smoothing` to every word count to get rid of zero probabilities. Since we add the same amount to every count in the numerator and denominator, we maintain a valid probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "from collections import Counter\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self, C: list, vocab_size: int, smoothing=0.05):\n",
    "        assert vocab_size > 0\n",
    "\n",
    "        self.C = C\n",
    "        self.vocab_size = vocab_size\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def train(self, D: list):\n",
    "        big = []\n",
    "        for i in range(len(D)):\n",
    "            big.extend(D[i][0])\n",
    "        counts = Counter(big)\n",
    "        self.V = [tup[0] for tup in counts.most_common(self.vocab_size)]\n",
    "\n",
    "        N_doc = len(D)\n",
    "        self.logpriors = []\n",
    "        self.bigdoc = []\n",
    "        self.loglikelihood = [[] for _ in range(self.vocab_size)]\n",
    "        for i in range(len(self.C)): # calculate P(c) terms\n",
    "            c = self.C[i]\n",
    "            print('Training %d' % c)\n",
    "\n",
    "            N_c = 0\n",
    "            self.bigdoc.append([])\n",
    "            for sample in D:\n",
    "                if sample[1] == c:\n",
    "                    N_c += 1\n",
    "                    self.bigdoc[i].extend(sample[0])\n",
    "            self.logpriors.append(log2(N_c / N_doc))\n",
    "            print(' %d samples' % N_c)\n",
    "            print(' log P(c) = %f. Counting word occurrences...' % self.logpriors[i])\n",
    "            sum = 0\n",
    "            counts = Counter(self.bigdoc[i])\n",
    "            for w_prime in self.V:\n",
    "                sum += counts[w_prime] + self.smoothing\n",
    "            count = 0\n",
    "            print(' Counted %d occurrences, now computing log P(w|c)s...' % sum)\n",
    "            for j in range(self.vocab_size): # calculate P(w|c) terms\n",
    "                count += 1\n",
    "                w = self.V[j]\n",
    "                self.loglikelihood[j].append(log2((counts[w] + self.smoothing) / sum))\n",
    "\n",
    "    def test(self, testdoc):\n",
    "        max_prob, max_c = -1000000, None\n",
    "        for i in range(len(self.C)):\n",
    "            class_prob = self.logpriors[i]\n",
    "            for word in testdoc:\n",
    "                if word in self.V:\n",
    "                    index = self.V.index(word)\n",
    "                    class_prob += self.loglikelihood[index][i]\n",
    "            if class_prob > max_prob:\n",
    "                max_prob = class_prob\n",
    "                max_c = self.C[i]\n",
    "        return max_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be able to evaluate our predictions, so for now we will just compute the recall of each class with a simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, y_pred, tp, fp, tn, fn, tneu, fneu):\n",
    "    if y == -1:\n",
    "        if y_pred == -1:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    elif y == 0:\n",
    "        if y_pred == 0:\n",
    "            tneu += 1\n",
    "        else:\n",
    "            fneu += 1\n",
    "    else:\n",
    "        if y_pred == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    return (tp, fp, tn, fn, tneu, fneu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -1\n",
      " 28151 samples\n",
      " log P(c) = -2.204365. Counting word occurrences...\n",
      " Counted 599221 occurrences, now computing log P(w|c)s...\n",
      "Training 0\n",
      " 43970 samples\n",
      " log P(c) = -1.561032. Counting word occurrences...\n",
      " Counted 554936 occurrences, now computing log P(w|c)s...\n",
      "Training 1\n",
      " 57619 samples\n",
      " log P(c) = -1.171007. Counting word occurrences...\n",
      " Counted 1168327 occurrences, now computing log P(w|c)s...\n",
      "Testing 32436 samples\n",
      " 5000 samples, tpr 0.830660 tneur 0.777712 tnr 0.757754\n",
      " 10000 samples, tpr 0.836054 tneur 0.778696 tnr 0.766779\n",
      " 15000 samples, tpr 0.841556 tneur 0.773861 tnr 0.763688\n",
      " 20000 samples, tpr 0.842736 tneur 0.779944 tnr 0.756875\n",
      " 25000 samples, tpr 0.846267 tneur 0.784471 tnr 0.753097\n",
      " 30000 samples, tpr 0.849014 tneur 0.779122 tnr 0.752404\n",
      "positive recall %: 84.784897\n",
      "neutral recall %: 77.753524\n",
      "negative recall %: 75.152948\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 5000\n",
    "model = NaiveBayesClassifier(classes, vocab_size)\n",
    "model.train(train)\n",
    "print('Testing %d samples' % len(test))\n",
    "tp, fp, tn, fn, tneu, fneu, count = 0, 0, 0, 0, 0, 0, 0\n",
    "for sample in test:\n",
    "    count += 1\n",
    "    y = sample[1]\n",
    "    y_pred = model.test(sample[0])\n",
    "    tp, fp, tn, fn, tneu, fneu = evaluate(y, y_pred, tp, fp, tn, fn, tneu, fneu)\n",
    "    if count % 5000 == 0:\n",
    "        print(' %d samples, tpr %f tneur %f tnr %f' % (count, (tp / (tp + fp)), (tneu / (tneu + fneu)), (tn / (tn + fn))))\n",
    "\n",
    "print('positive recall %%: %f' % (100 * tp / (tp + fp)))\n",
    "print('neutral recall %%: %f' % (100 * tneu / (tneu + fneu)))\n",
    "print('negative recall %%: %f' % (100 * tn / (tn + fn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
